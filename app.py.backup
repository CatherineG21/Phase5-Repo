"""
CIT Loss Prediction System - Web Application
KRA Corporate Income Tax Risk Assessment
"""
from flask import Flask, render_template, request, jsonify, send_file
import joblib
import pandas as pd
import numpy as np
import os
import json
from datetime import datetime
import xgboost as xgb
import io
import csv

app = Flask(__name__)

# Global variables for model
MODEL = None
PIPELINE = None
FEATURE_NAMES = None
THRESHOLD = 0.5

def load_model():
    """Load the trained model and preprocessing artifacts"""
    global MODEL, PIPELINE, FEATURE_NAMES, THRESHOLD
    
    try:
        model_path = "deployment_artifacts/kra_cit_risk_model_v1.pkl"
        
        if not os.path.exists(model_path):
            return False, "Model file not found"
        
        print(f"Loading model from: {model_path}")
        bundle = joblib.load(model_path)
        
        # Extract components
        MODEL = bundle['model']
        PIPELINE = bundle['pipeline']
        FEATURE_NAMES = bundle['feature_names']
        THRESHOLD = bundle.get('threshold', 0.5)
        
        print(f"âœ… Model loaded successfully")
        print(f"   Model type: {type(MODEL).__name__}")
        print(f"   Feature count: {len(FEATURE_NAMES)}")
        print(f"   Threshold: {THRESHOLD}")
        
        return True, "Model loaded successfully"
        
    except Exception as e:
        error_msg = f"Error loading model: {str(e)}"
        print(f"âŒ {error_msg}")
        return False, error_msg

def create_input_dataframe(form_data):
    """Create a DataFrame from form data"""
    # Map form fields to expected feature names
    # Based on your notebook, these are the 9 main features
    input_dict = {
        'cost_to_turnover': float(form_data.get('cost_to_turnover', 0)),
        'admin_cost_ratio': float(form_data.get('admin_cost_ratio', 0)),
        'employment_cost_ratio': float(form_data.get('employment_cost_ratio', 0)),
        'financing_cost_ratio': float(form_data.get('financing_cost_ratio', 0)),
        'deductions_to_turnover': float(form_data.get('deductions_to_turnover', 0)),
        'high_cost_flag': int(form_data.get('high_cost_flag', 0)),
        'thin_margin_flag': int(form_data.get('thin_margin_flag', 0)),
        'turnover_bin_q': form_data.get('turnover_bin_q', 'Q1'),
        'sector': form_data.get('sector', 'CONSTRUCTION')
    }
    
    # Add other required fields with default values
    # These are needed because the pipeline expects them
    additional_fields = {
        'grossturnover': float(form_data.get('grossturnover', 1000000)),
        'cost_of_sales': float(form_data.get('cost_of_sales', 500000)),
        'total_administrative_exp': float(form_data.get('total_administrative_exp', 100000)),
        'total_employment_exp': float(form_data.get('total_employment_exp', 50000)),
        'total_financing_exp': float(form_data.get('total_financing_exp', 20000)),
        'tot_allow_deductions': float(form_data.get('tot_allow_deductions', 5000)),
        'business_type': form_data.get('business_type', 'Company'),
        'business_subtype': form_data.get('business_subtype', 'Private Company'),
        'period_from': form_data.get('period_from', '1/1/2024'),
        'period_to': form_data.get('period_to', '31/12/2024'),
        'filing_date': form_data.get('filing_date', '30/04/2025'),
        'division_': form_data.get('division_', '411-General building construction'),
        'group_': form_data.get('group_', '4110-General building construction'),
        'total_other_income_int': float(form_data.get('total_other_income_int', 0))
    }
    
    # Merge all fields
    input_dict.update(additional_fields)
    
    # Create DataFrame
    df = pd.DataFrame([input_dict])
    return df

def get_risk_level(probability):
    """Determine risk level based on probability"""
    if probability >= 0.75:
        return "CRITICAL", "danger", "Immediate audit required"
    elif probability >= 0.5:
        return "HIGH", "warning", "Detailed review recommended"
    elif probability >= 0.3:
        return "MEDIUM", "info", "Monitor and review"
    else:
        return "LOW", "success", "Normal monitoring"

@app.route('/')
def home():
    """Render the home page"""
    return render_template('index.html')

@app.route('/predict', methods=['GET', 'POST'])
def predict():
    """Handle single prediction requests"""
    if request.method == 'GET':
        return render_template('predict.html')
    
    elif request.method == 'POST':
        try:
            # Check if model is loaded
            if MODEL is None:
                success, message = load_model()
                if not success:
                    return render_template('results.html', 
                                         error=f"Model not loaded: {message}")
            
            # Get form data
            form_data = request.form
            
            # Create input dataframe
            input_df = create_input_dataframe(form_data)
            
            # Apply preprocessing pipeline
            processed_data = PIPELINE.transform(input_df)
            
            # Create DMatrix for XGBoost
            dmatrix = xgb.DMatrix(processed_data, feature_names=FEATURE_NAMES)
            
            # Make prediction
            probability = MODEL.predict(dmatrix)[0]
            
            # Get risk level
            risk_level, risk_color, action = get_risk_level(probability)
            
            # Prepare results
            results = {
                'probability': round(probability * 100, 2),
                'raw_probability': round(probability, 4),
                'risk_level': risk_level,
                'risk_color': risk_color,
                'action': action,
                'threshold': round(THRESHOLD * 100, 2),
                'is_high_risk': probability >= THRESHOLD,
                'features': input_df.iloc[0].to_dict(),
                'timestamp': datetime.now().strftime("%Y-%m-%d %H:%M:%S")
            }
            
            return render_template('results.html', results=results)
            
        except Exception as e:
            error_msg = f"Prediction error: {str(e)}"
            print(f"âŒ {error_msg}")
            return render_template('results.html', error=error_msg)

@app.route('/batch', methods=['GET', 'POST'])
def batch_predict():
    """Handle batch predictions via file upload"""
    if request.method == 'GET':
        return render_template('batch.html')
    
    elif request.method == 'POST':
        try:
            # Check if model is loaded
            if MODEL is None:
                success, message = load_model()
                if not success:
                    return render_template('batch_results.html', 
                                         error=f"Model not loaded: {message}")
            
            # Check if file was uploaded
            if 'file' not in request.files:
                return render_template('batch_results.html', 
                                     error="No file uploaded")
            
            file = request.files['file']
            
            if file.filename == '':
                return render_template('batch_results.html', 
                                     error="No file selected")
            
            # Read the file
            if file.filename.endswith('.csv'):
                df = pd.read_csv(file)
            else:
                return render_template('batch_results.html', 
                                     error="Only CSV files are supported")
            
            # Process each row
            predictions = []
            for idx, row in df.iterrows():
                try:
                    # Convert row to dict
                    row_dict = row.to_dict()
                    
                    # Create input dataframe
                    input_df = create_input_dataframe(row_dict)
                    
                    # Apply preprocessing
                    processed_data = PIPELINE.transform(input_df)
                    
                    # Make prediction
                    dmatrix = xgb.DMatrix(processed_data, feature_names=FEATURE_NAMES)
                    probability = MODEL.predict(dmatrix)[0]
                    
                    # Get risk level
                    risk_level, _, _ = get_risk_level(probability)
                    
                    predictions.append({
                        'id': idx + 1,
                        'probability': round(probability * 100, 2),
                        'risk_level': risk_level,
                        'is_high_risk': probability >= THRESHOLD
                    })
                    
                except Exception as e:
                    predictions.append({
                        'id': idx + 1,
                        'error': str(e)
                    })
            
            # Count statistics
            high_risk_count = sum(1 for p in predictions if 'is_high_risk' in p and p['is_high_risk'])
            total_count = len(predictions)
            
            return render_template('batch_results.html', 
                                 predictions=predictions,
                                 total_count=total_count,
                                 high_risk_count=high_risk_count,
                                 threshold=THRESHOLD)
            
        except Exception as e:
            error_msg = f"Batch processing error: {str(e)}"
            print(f"âŒ {error_msg}")
            return render_template('batch_results.html', error=error_msg)

@app.route('/api/predict', methods=['POST'])
def api_predict():
    """API endpoint for predictions"""
    try:
        # Check if model is loaded
        if MODEL is None:
            success, message = load_model()
            if not success:
                return jsonify({'error': f'Model not loaded: {message}'}), 500
        
        # Get JSON data
        data = request.json
        
        # Create input dataframe
        input_df = create_input_dataframe(data)
        
        # Apply preprocessing
        processed_data = PIPELINE.transform(input_df)
        
        # Make prediction
        dmatrix = xgb.DMatrix(processed_data, feature_names=FEATURE_NAMES)
        probability = MODEL.predict(dmatrix)[0]
        
        # Get risk level
        risk_level, _, action = get_risk_level(probability)
        
        return jsonify({
            'success': True,
            'probability': float(probability),
            'risk_level': risk_level,
            'action': action,
            'is_high_risk': probability >= THRESHOLD,
            'timestamp': datetime.now().isoformat()
        })
        
    except Exception as e:
        return jsonify({'error': str(e)}), 500

@app.route('/health')
def health_check():
    """Health check endpoint"""
    if MODEL is not None:
        return jsonify({'status': 'healthy', 'model_loaded': True})
    else:
        return jsonify({'status': 'loading', 'model_loaded': False})

@app.route('/model-info')
def model_info():
    """Get model information"""
    if MODEL is None:
        return jsonify({'error': 'Model not loaded'}), 404
    
    return jsonify({
        'model_type': type(MODEL).__name__,
        'feature_count': len(FEATURE_NAMES) if FEATURE_NAMES else 0,
        'threshold': THRESHOLD,
        'loaded': True
    })

# Load model when app starts
print("ðŸš€ Starting CIT Loss Prediction System...")
load_model()

if __name__ == '__main__':
    app.run(debug=True, host='0.0.0.0', port=5000)
